{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "044d9c6a",
   "metadata": {},
   "source": [
    "# 2025 데이터 크리에이터 캠프\n",
    "\n",
    "@PHASE: Mission 2\n",
    "\n",
    "@TEAM: 최후의 인공지능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b5ea4cfae13401",
   "metadata": {},
   "source": [
    "## Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "id": "a7e888eba8b18b17",
   "metadata": {},
   "source": [
    "!nvidia-smi"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5efa704fa81e6072",
   "metadata": {},
   "source": [
    "# Set CUDA Device Number\n",
    "DEVICE_NUM = 1\n",
    "ADDITIONAL_GPU = 0\n",
    "\n",
    "from os import environ\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([f\"{i+DEVICE_NUM}\" for i in range(0, ADDITIONAL_GPU+1)])\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "066676dc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.getcwd()"
   ],
   "id": "bccc990a5a2ac1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "os.chdir(\"/home/ubuntu/test_trainer/src\")",
   "id": "ba41a6f8771c99f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2b08ea64",
   "metadata": {},
   "source": [
    "from os import path\n",
    "\n",
    "from creator_camp.datasets import KompsatDatasetForHeightRegression, DatasetHolder\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet101, ResNet101_Weights\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "23ffd3da4d752be5",
   "metadata": {},
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"INFO: Using device - {device}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f52e1c723f76fc4f",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "973243d0d0632803",
   "metadata": {},
   "source": [
    "DATA_ROOT = path.join(\".\", \"data\")\n",
    "\n",
    "kompstats = DatasetHolder(\n",
    "    train=KompsatDatasetForHeightRegression(root=DATA_ROOT, train=True),\n",
    "    valid=KompsatDatasetForHeightRegression(root=DATA_ROOT, train=False)\n",
    ")\n",
    "kompstats.test = kompstats.valid"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e1973a6e3a7a4f27",
   "metadata": {},
   "source": [
    "kompstats.train[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "49d102cd1b5fdcc1",
   "metadata": {},
   "source": [
    "rgb_image, annotation = kompstats.train[0]\n",
    "fig, axes = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "axes.imshow(rgb_image)\n",
    "axes.set_title('Image')\n",
    "axes.axis('off')\n",
    "\n",
    "for region in annotation['regions']:\n",
    "    x1, y1, w, h = region['xywh']\n",
    "    rect = plt.Rectangle((x1, y1), w, h, fill=False, edgecolor='red', linewidth=2)\n",
    "    axes.add_patch(rect)\n",
    "\n",
    "    polyline = region['polyline']\n",
    "    xs = [polyline[0], polyline[2]]\n",
    "    ys = [polyline[1], polyline[3]]\n",
    "    axes.plot(xs, ys, color='blue', linewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def target_transform(data):\n",
    "    regions = data['regions']\n",
    "    polylines = []\n",
    "    heights = []\n",
    "    for region in regions:\n",
    "        polyline = region['xywh']\n",
    "        height = region['chi_height']\n",
    "        polylines.append(polyline)\n",
    "        heights.append(height)\n",
    "    return torch.tensor(polylines), torch.tensor(heights) / 100"
   ],
   "id": "acf5ad3ca11f80de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "kompstats.train.transform = transforms.ToTensor()\n",
    "kompstats.valid.transform = transforms.ToTensor()\n",
    "kompstats.train.target_transform = target_transform\n",
    "kompstats.valid.target_transform = target_transform"
   ],
   "id": "cc10cf8f34ed035",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "kompstats.train[0]",
   "id": "95557966a7fedc94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DataLoader",
   "id": "42bdb9913b15b4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set Batch Size\n",
    "BATCH_SIZE = 128, 256, 256  # A100\n",
    "\n",
    "print(f\"INFO: Set batch size - Train: {BATCH_SIZE[0]}, Valid: {BATCH_SIZE[1]}, Test: {BATCH_SIZE[2]}\")"
   ],
   "id": "d012c108dcc062bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    coords, heights = zip(*labels)\n",
    "    return torch.stack(images), coords, heights"
   ],
   "id": "708a96098aa913cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(kompstats.train, batch_size=BATCH_SIZE[0], shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(kompstats.valid, batch_size=BATCH_SIZE[1], shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(kompstats.test, batch_size=BATCH_SIZE[2], shuffle=False, collate_fn=collate_fn)"
   ],
   "id": "404b6700646635a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "load_samples = train_loader.__iter__().__next__()\n",
    "load_samples"
   ],
   "id": "aca8c0c615f9bfac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "load_samples[0].shape",
   "id": "7a1d50a95c266b50",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4e4053c037f244da",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SwinForHeightRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        resnet = resnet101(weights=ResNet101_Weights.DEFAULT)\n",
    "        self.model = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        self.coords_embedding = nn.Linear(4, 2048)\n",
    "        self.decoder_height = 1\n",
    "        self.cross_attentions = nn.ModuleList([nn.MultiheadAttention(\n",
    "            embed_dim=2048,\n",
    "            num_heads=64,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        ) for _ in range(self.decoder_height)])\n",
    "        self.head = nn.Linear(2048, 1)\n",
    "\n",
    "    def forward(self, pixel_values, polylines):\n",
    "        outputs = self.model(pixel_values.to(device).bfloat16()).flatten(2).transpose(1, 2)\n",
    "        results = []\n",
    "\n",
    "        for hidden_states, polyline in zip(outputs, polylines):\n",
    "            coords_embed = self.coords_embedding(polyline.to(device).bfloat16()).unsqueeze(0)\n",
    "\n",
    "            key_and_value = hidden_states.unsqueeze(0)\n",
    "            for cross_attn in self.cross_attentions:\n",
    "                coords_embed, _ = cross_attn(coords_embed, key_and_value, key_and_value)\n",
    "\n",
    "            results.append(self.head(coords_embed).reshape(-1))\n",
    "        return results"
   ],
   "id": "26eb3d4ba8ce9888",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = SwinForHeightRegression()\n",
    "model.bfloat16().to(device)"
   ],
   "id": "3eda135661c18828",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "53dfdb161ae65bd5",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "id": "b36691d14503ca21",
   "metadata": {},
   "source": [
    "# Set Epoch Count & Learning Rate\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-4, 1e-6"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "classifier = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE[0], weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=LEARNING_RATE[1])"
   ],
   "id": "335029cddea84e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for epoch in tqdm(range(EPOCHS), desc=\"Running Epochs\"):\n",
    "    train_loss, valid_loss = 0, 0\n",
    "    train_rmse, valid_rmse = 0, 0\n",
    "\n",
    "    model.train()\n",
    "    train_bar = tqdm(total=int(len(kompstats.train)/BATCH_SIZE[0]+0.5), desc=f\"Training for {epoch+1}/{EPOCHS}\")\n",
    "    for inputs, coords, heights in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(inputs, coords)\n",
    "        all_preds = torch.cat([pred.flatten() for pred in preds])\n",
    "        all_heights = torch.cat([height.flatten() for height in heights]).to(device).to(all_preds.dtype)\n",
    "\n",
    "        losses = classifier(all_preds, all_heights)\n",
    "        rmse = torch.sqrt(classifier(all_preds*100, all_heights*100))\n",
    "        losses.backward()\n",
    "\n",
    "        train_loss += losses.item()\n",
    "        train_rmse += rmse.item()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_bar.update(1)\n",
    "        train_bar.set_postfix({\"Loss\": f\"{losses.item():.6f}\", \"RMSE\": rmse.item()})\n",
    "    train_bar.set_postfix({\"Loss\": f\"{train_loss / train_bar.total:.6f}\", \"RMSE\": train_rmse / train_bar.total})\n",
    "    train_bar.close()\n",
    "\n",
    "    model.eval()\n",
    "    valid_bar = tqdm(total=int(len(kompstats.valid)/BATCH_SIZE[1]+0.5), desc=f\"Validating for {epoch+1}/{EPOCHS}\")\n",
    "    with torch.inference_mode():\n",
    "        for inputs, coords, heights in valid_loader:\n",
    "            preds = model(inputs, coords)\n",
    "            all_preds = torch.cat([pred.flatten() for pred in preds])\n",
    "            all_heights = torch.cat([height.flatten() for height in heights]).to(device).to(all_preds.dtype)\n",
    "\n",
    "            losses = classifier(all_preds, all_heights)\n",
    "            rmse = torch.sqrt(classifier(all_preds*100, all_heights*100))\n",
    "\n",
    "            valid_loss += losses.item()\n",
    "            valid_rmse += rmse.item()\n",
    "            valid_bar.update(1)\n",
    "\n",
    "    valid_bar.set_postfix({\"Loss\": f\"{valid_loss / valid_bar.total:.6f}\", \"RMSE\": valid_rmse / valid_bar.total})\n",
    "    valid_bar.close()\n",
    "\n",
    "    scheduler.step()"
   ],
   "id": "c66e7ecd9ece4612",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6f0aace760f618d0",
   "metadata": {},
   "source": " ## Evaluate"
  },
  {
   "cell_type": "code",
   "id": "e9a3a7e501e093d2",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-trainer",
   "language": "python",
   "name": "test-trainer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
