{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "044d9c6a",
   "metadata": {},
   "source": [
    "# 2025 데이터 크리에이터 캠프\n",
    "\n",
    "@PHASE: Mission 1\n",
    "\n",
    "@TEAM: 최후의 인공지능"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check GPU Availability",
   "id": "95b5ea4cfae13401"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!nvidia-smi",
   "id": "a7e888eba8b18b17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set CUDA Device Number\n",
    "DEVICE_NUM = 0\n",
    "ADDITIONAL_GPU = 0\n",
    "\n",
    "from os import environ\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([f\"{i+DEVICE_NUM}\" for i in range(0, ADDITIONAL_GPU+1)])\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"]"
   ],
   "id": "5efa704fa81e6072"
  },
  {
   "cell_type": "markdown",
   "id": "066676dc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "2b08ea64",
   "metadata": {},
   "source": [
    "from os import path\n",
    "\n",
    "from creator_camp.datasets import KompsatDataset, SentinelDataset, DatasetHolder\n",
    "\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "\n",
    "from supervision.metrics.mean_average_precision import MeanAveragePrecision\n",
    "from supervision.detection.core import Detections\n",
    "\n",
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if torch.cuda.is_available():\n",
    "    if ADDITIONAL_GPU:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda\")  # torch.device(f\"cuda:{DEVICE_NUM}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    DEVICE_NUM = -1\n",
    "\n",
    "print(f\"INFO: Using device - {device}\" + (f\":{DEVICE_NUM}\" if ADDITIONAL_GPU else \"\"))"
   ],
   "id": "23ffd3da4d752be5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "PROJECT_NAME = \"Mission_1\"\n",
    "RUN_NAME = \"RT-DETR\"\n",
    "\n",
    "# WandB Initialization\n",
    "wandb.init(project=PROJECT_NAME, name=RUN_NAME)"
   ],
   "id": "9215d175116b3ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Dataset",
   "id": "f52e1c723f76fc4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "DATA_ROOT = path.join(\".\", \"data\")\n",
    "\n",
    "kompstats = DatasetHolder(train=KompsatDataset(root=DATA_ROOT, train=True), valid=KompsatDataset(root=DATA_ROOT, train=False))\n",
    "sentinels = DatasetHolder(train=SentinelDataset(root=DATA_ROOT, train=True), valid=SentinelDataset(root=DATA_ROOT, train=False))"
   ],
   "id": "973243d0d0632803"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "kompstats.train[0]",
   "id": "e1973a6e3a7a4f27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "sentinels.train[0]",
   "id": "8543a62dca23e645"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rgb_image, mask_image = sentinels.train[0]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axes[0].imshow(rgb_image)\n",
    "axes[0].set_title('Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(mask_image, cmap='gray')\n",
    "axes[1].set_title(\"Mask\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "49d102cd1b5fdcc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DataLoader",
   "id": "3752cebd36e5c809"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set Batch Size\n",
    "BATCH_SIZE = 2, 8, 8, 8  # 4070 Ti\n",
    "#BATCH_SIZE = 32, 64, 64, 32  # A6000\n",
    "\n",
    "# Dataset Configs\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "print(f\"INFO: Set batch size - Train: {BATCH_SIZE[0]}, Valid: {BATCH_SIZE[1]}, Test: {BATCH_SIZE[2]}\")"
   ],
   "id": "d3d124eb51bc123a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def collate_fn(batch, preprocessor=None):\n",
    "    images = [item['image'] for item in batch]\n",
    "    target = [item['target'] for item in batch]\n",
    "    return preprocessor(images=images, annotations=target, return_tensors=\"pt\")"
   ],
   "id": "230530fa899d5c51"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Model",
   "id": "4e4053c037f244da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import AutoBackbone, RTDetrForObjectDetection, RTDetrImageProcessorFast, RTDetrConfig\n",
    "from transformers.image_utils import AnnotationFormat"
   ],
   "id": "eebf1c3ff5b91ae6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "reference_model_id = \"PekingU/rtdetr_r101vd\"\n",
    "\n",
    "# Load the reference model configuration\n",
    "reference_config = RTDetrConfig.from_pretrained(reference_model_id, torch_dtype=torch.float32, return_dict=True)\n",
    "reference_config.num_labels = NUM_CLASSES\n",
    "\n",
    "# Set the image size and preprocessor size\n",
    "reference_config.image_size = 640\n",
    "\n",
    "# Load the reference model image processor\n",
    "reference_preprocessor = RTDetrImageProcessorFast.from_pretrained(reference_model_id)\n",
    "reference_preprocessor.format = AnnotationFormat.COCO_DETECTION  # COCO Format / Detection BBOX Format\n",
    "reference_preprocessor.size = {\"height\": 640, \"width\": 640}\n",
    "reference_preprocessor.do_resize = True\n",
    "# ---\n",
    "test_img_size = 896\n",
    "test_preprocessor = RTDetrImageProcessorFast.from_pretrained(reference_model_id)\n",
    "test_preprocessor.format = AnnotationFormat.COCO_DETECTION  # COCO Format / Detection BBOX Format\n",
    "test_preprocessor.size = {\"height\": test_img_size, \"width\": test_img_size}\n",
    "test_preprocessor.do_resize = True"
   ],
   "id": "ad4b44b1439d76ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = RTDetrForObjectDetection.from_pretrained(reference_model_id, config=reference_config, torch_dtype=torch.float32, ignore_mismatched_sizes=True)\n",
    "model.to(device)"
   ],
   "id": "44373f47d600fb82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers.trainer_utils import EvalPrediction\n",
    "from torchvision.ops import box_convert\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelOutput:\n",
    "    logits: torch.Tensor\n",
    "    pred_boxes: torch.Tensor\n",
    "\n",
    "\n",
    "def de_normalize_boxes(boxes, height, width):\n",
    "    # 1. cxcywh → xyxy\n",
    "    boxes_xyxy_norm = box_convert(boxes, 'cxcywh', 'xyxy')\n",
    "\n",
    "    # 2. de-normalize (convert to actual pixel coordinates)\n",
    "    boxes_xyxy_norm[:, [0, 2]] *= width\n",
    "    boxes_xyxy_norm[:, [1, 3]] *= height\n",
    "    return boxes_xyxy_norm\n",
    "\n",
    "\n",
    "def map_compute_metrics(preprocessor=reference_preprocessor, threshold=0.0):\n",
    "    map_metric = MeanAveragePrecision()\n",
    "    post_process = preprocessor.post_process_object_detection\n",
    "\n",
    "    def calc(eval_pred: EvalPrediction, compute_result=False):\n",
    "        nonlocal map_metric\n",
    "\n",
    "        if compute_result:\n",
    "            m_ap = map_metric.compute()\n",
    "            map_metric.reset()\n",
    "\n",
    "            return {\n",
    "                \"mAP@0.50:0.95\": m_ap.map50_95,\n",
    "                \"mAP@0.50\": m_ap.map50,\n",
    "                \"mAP@0.75\": m_ap.map75\n",
    "            }\n",
    "        else:\n",
    "            preds = ModelOutput(*eval_pred.predictions[1:3])\n",
    "            labels = eval_pred.label_ids\n",
    "            sizes = [label['orig_size'].cpu().tolist() for label in labels]\n",
    "\n",
    "            results = post_process(preds, target_sizes=sizes, threshold=threshold)\n",
    "            predictions = [Detections.from_transformers(result) for result in results]\n",
    "            targets = [Detections(\n",
    "                xyxy=de_normalize_boxes(label['boxes'], *label['orig_size']).cpu().numpy(),\n",
    "                class_id=label['class_labels'].cpu().numpy(),\n",
    "            ) for label in labels]\n",
    "\n",
    "            map_metric.update(predictions=predictions, targets=targets)\n",
    "            return {}\n",
    "    return calc, map_metric"
   ],
   "id": "c54e913edc10cfef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train",
   "id": "53dfdb161ae65bd5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set Epoch Count & Learning Rate\n",
    "EPOCHS = 20\n",
    "REAL_BATCH = BATCH_SIZE[-1]\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    backbone_lr=LEARNING_RATE/10,  # Set backbone learning rate to 1/10th of the main learning rate\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.1,\n",
    "    max_grad_norm=0.5,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE[0],\n",
    "    per_device_eval_batch_size=BATCH_SIZE[1],\n",
    "    gradient_accumulation_steps=REAL_BATCH//BATCH_SIZE[0],\n",
    "    eval_accumulation_steps=BATCH_SIZE[1],\n",
    "    batch_eval_metrics=True,\n",
    "    remove_unused_columns=False,\n",
    "    optim=\"adamw_torch\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"mAP@0.50\",\n",
    "    greater_is_better=True,\n",
    "    #metric_for_best_model=\"eval_loss\",\n",
    "    #greater_is_better=False,\n",
    "    report_to=\"wandb\",\n",
    "    output_dir=\"./results/\"+RUN_NAME,\n",
    "    logging_dir=\"./logs/\"+RUN_NAME,\n",
    "    run_name=RUN_NAME,\n",
    "    bf16=True,\n",
    ")\n",
    "\n",
    "testing_args = TrainingArguments(\n",
    "    per_device_eval_batch_size=BATCH_SIZE[2],\n",
    "    batch_eval_metrics=True,\n",
    "    remove_unused_columns=False,\n",
    ")"
   ],
   "id": "b36691d14503ca21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from functools import partial\n",
    "\n",
    "compute_metrics, compute_results = map_compute_metrics(preprocessor=reference_preprocessor)\n",
    "test_compute_metrics, test_compute_results = map_compute_metrics(preprocessor=test_preprocessor)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=kompstats.train,\n",
    "    eval_dataset=kompstats.valid,\n",
    "    data_collator=partial(collate_fn, preprocessor=reference_preprocessor),\n",
    "    compute_metrics=compute_metrics,\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=30)]\n",
    ")\n",
    "\n",
    "tester = Trainer(\n",
    "    model=model,\n",
    "    args=testing_args,\n",
    "    eval_dataset=kompstats.valid,\n",
    "    data_collator=partial(collate_fn, preprocessor=test_preprocessor),\n",
    "    compute_metrics=test_compute_metrics\n",
    ")"
   ],
   "id": "c5273c531e2c1858"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def start_train():\n",
    "    accelerator = Accelerator()\n",
    "    while True:\n",
    "        try:\n",
    "            try:\n",
    "                print(\"INFO: Trying to resume from previous checkpoint\")\n",
    "                compute_results.reset()\n",
    "                trainer.train(resume_from_checkpoint=True)\n",
    "            except Exception as e:\n",
    "                if \"No valid checkpoint found\" in str(e):\n",
    "                    print(f\"ERROR: Failed to resume from checkpoint - {e}\")\n",
    "                    print(\"INFO: Starting training from scratch\")\n",
    "                    compute_results.reset()\n",
    "                    trainer.train(resume_from_checkpoint=False)\n",
    "        except Exception as e:\n",
    "            if \"CUDA\" in str(e):\n",
    "                print(f\"ERROR: CUDA Error - {e}\")\n",
    "                trainer.train()\n",
    "            else:\n",
    "                raise e"
   ],
   "id": "3db2a1e328759ba2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if ADDITIONAL_GPU:\n",
    "    notebook_launcher(start_train, args=(), num_processes=ADDITIONAL_GPU)\n",
    "else:\n",
    "    start_train()"
   ],
   "id": "d8127090f2f63c77"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate",
   "id": "6f0aace760f618d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer.evaluate()",
   "id": "18b420442c9a00c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tester.evaluate()",
   "id": "76b5655e026216c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "checkpoint = 31100",
   "id": "c6b0e803b70cf08a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "try:\n",
    "    model = RTDetrForObjectDetection.from_pretrained(f\"{training_args.output_dir}/checkpoint-{checkpoint}/\", torch_dtype=torch.float32, return_dict=True, local_files_only=True)\n",
    "    model.to(device)\n",
    "except Exception:\n",
    "    pass"
   ],
   "id": "4508ab0fd10e41f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2b59c9498f5db854"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creator-camp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
