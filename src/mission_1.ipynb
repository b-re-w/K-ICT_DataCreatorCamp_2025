{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "044d9c6a",
   "metadata": {},
   "source": [
    "# 2025 데이터 크리에이터 캠프\n",
    "\n",
    "@PHASE: Mission 1\n",
    "\n",
    "@TEAM: 최후의 인공지능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b5ea4cfae13401",
   "metadata": {},
   "source": [
    "## Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e888eba8b18b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa704fa81e6072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA Device Number\n",
    "DEVICE_NUM = 0\n",
    "ADDITIONAL_GPU = 0\n",
    "\n",
    "from os import environ\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([f\"{i+DEVICE_NUM}\" for i in range(0, ADDITIONAL_GPU+1)])\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066676dc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b08ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "from creator_camp.datasets import KompsatDatasetForObjectDetection, DatasetHolder\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "\n",
    "from supervision.metrics.mean_average_precision import MeanAveragePrecision\n",
    "from supervision.detection.core import Detections\n",
    "\n",
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ffd3da4d752be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    if ADDITIONAL_GPU:\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda\")  # torch.device(f\"cuda:{DEVICE_NUM}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    DEVICE_NUM = -1\n",
    "\n",
    "print(f\"INFO: Using device - {device}\" + (f\":{DEVICE_NUM}\" if ADDITIONAL_GPU else \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9215d175116b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"Mission_1\"\n",
    "RUN_NAME = \"RT-DETR\"\n",
    "\n",
    "# WandB Initialization\n",
    "wandb.init(project=PROJECT_NAME, name=RUN_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52e1c723f76fc4f",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973243d0d0632803",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = path.join(\".\", \"data\")\n",
    "\n",
    "kompstats = DatasetHolder(train=KompsatDatasetForObjectDetection(root=DATA_ROOT, train=True), valid=KompsatDatasetForObjectDetection(root=DATA_ROOT, train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1973a6e3a7a4f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "kompstats.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d102cd1b5fdcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_image, _ = kompstats.train[0]\n",
    "fig, axes = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "axes.imshow(rgb_image)\n",
    "axes.set_title('Image')\n",
    "axes.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3752cebd36e5c809",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d124eb51bc123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Batch Size\n",
    "BATCH_SIZE = 4, 8, 8, 8  # Local\n",
    "#BATCH_SIZE = 32, 64, 64, 32  # A100\n",
    "\n",
    "# Dataset Configs\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "print(f\"INFO: Set batch size - Train: {BATCH_SIZE[0]}, Valid: {BATCH_SIZE[1]}, Test: {BATCH_SIZE[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230530fa899d5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch, preprocessor):\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = []\n",
    "    evals = []\n",
    "\n",
    "    for annotations in [item[1] for item in batch]:\n",
    "        attrs = annotations['file_attributes']\n",
    "        targets.append(dict(image_id=len(targets), annotations=[dict(\n",
    "            bbox=reg['xywh'],  # COCO format\n",
    "            category_id=0,\n",
    "            area=attrs['img_width'] * attrs['img_height'],\n",
    "            iscrowd=0\n",
    "        ) for reg in annotations['regions']]))\n",
    "        evals.append([reg['xyxy'] for reg in annotations['regions']])\n",
    "\n",
    "    processed = preprocessor(images=images, annotations=targets, return_tensors=\"pt\")  # bbox converted to cxcywh format & normalized\n",
    "    for label, bbox in zip(processed['labels'], evals):\n",
    "        label['eval_bbox'] = torch.tensor(bbox) if len(bbox) else torch.empty((0, 4), dtype=torch.float32)  # add xyxy bbox for evaluation\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4053c037f244da",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf1c3ff5b91ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RTDetrForObjectDetection, RTDetrImageProcessorFast, RTDetrConfig\n",
    "from transformers.image_utils import AnnotationFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b44b1439d76ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_model_id = \"PekingU/rtdetr_r101vd\"\n",
    "\n",
    "# Load the reference model configuration\n",
    "reference_config = RTDetrConfig.from_pretrained(reference_model_id, torch_dtype=torch.float32, return_dict=True)\n",
    "reference_config.num_labels = NUM_CLASSES + 1\n",
    "\n",
    "# Set the image size and preprocessor size\n",
    "reference_config.image_size = 640\n",
    "\n",
    "# Load the reference model image processor\n",
    "reference_preprocessor = RTDetrImageProcessorFast.from_pretrained(reference_model_id)\n",
    "reference_preprocessor.format = AnnotationFormat.COCO_DETECTION  # COCO Format / Detection BBOX Format\n",
    "reference_preprocessor.size = {\"height\": 640, \"width\": 640}\n",
    "reference_preprocessor.do_resize = True\n",
    "# ---\n",
    "test_img_size = 1024\n",
    "test_preprocessor = RTDetrImageProcessorFast.from_pretrained(reference_model_id)\n",
    "test_preprocessor.format = AnnotationFormat.COCO_DETECTION  # COCO Format / Detection BBOX Format\n",
    "test_preprocessor.size = {\"height\": test_img_size, \"width\": test_img_size}\n",
    "test_preprocessor.do_resize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44373f47d600fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RTDetrForObjectDetection.from_pretrained(reference_model_id, config=reference_config, torch_dtype=torch.float32, ignore_mismatched_sizes=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54e913edc10cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_utils import EvalPrediction\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelOutput:\n",
    "    logits: torch.Tensor\n",
    "    pred_boxes: torch.Tensor\n",
    "\n",
    "\n",
    "def map_compute_metrics(preprocessor=reference_preprocessor, threshold=0.0):\n",
    "    map_metric = MeanAveragePrecision()\n",
    "    post_process = preprocessor.post_process_object_detection\n",
    "\n",
    "    def calc(eval_pred: EvalPrediction, compute_result=False):\n",
    "        nonlocal map_metric\n",
    "\n",
    "        if compute_result:\n",
    "            m_ap = map_metric.compute()\n",
    "            map_metric.reset()\n",
    "\n",
    "            return {\n",
    "                \"mAP@0.50:0.95\": m_ap.map50_95,\n",
    "                \"mAP@0.50\": m_ap.map50,\n",
    "                \"mAP@0.75\": m_ap.map75\n",
    "            }\n",
    "        else:\n",
    "            preds = ModelOutput(*eval_pred.predictions[1:3])\n",
    "            labels = eval_pred.label_ids\n",
    "            sizes = [label['orig_size'].cpu().tolist() for label in labels]\n",
    "\n",
    "            results = post_process(preds, target_sizes=sizes, threshold=threshold)\n",
    "            predictions = [Detections.from_transformers(result) for result in results]\n",
    "            targets = [Detections(\n",
    "                xyxy=label['eval_bbox'].detach().cpu().numpy(),\n",
    "                class_id=label['class_labels'].detach().cpu().numpy(),\n",
    "            ) for label in labels]\n",
    "\n",
    "            map_metric.update(predictions=predictions, targets=targets)\n",
    "            return {}\n",
    "    return calc, map_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dfdb161ae65bd5",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36691d14503ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Epoch Count & Learning Rate\n",
    "EPOCHS = 5\n",
    "REAL_BATCH = BATCH_SIZE[-1]\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.1,\n",
    "    max_grad_norm=0.5,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE[0],\n",
    "    per_device_eval_batch_size=BATCH_SIZE[1],\n",
    "    gradient_accumulation_steps=REAL_BATCH//BATCH_SIZE[0],\n",
    "    eval_accumulation_steps=BATCH_SIZE[1],\n",
    "    batch_eval_metrics=True,\n",
    "    remove_unused_columns=False,\n",
    "    optim=\"adamw_torch\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"mAP@0.50\",\n",
    "    greater_is_better=True,\n",
    "    #metric_for_best_model=\"eval_loss\",\n",
    "    #greater_is_better=False,\n",
    "    report_to=\"wandb\",\n",
    "    output_dir=\"./results/\"+RUN_NAME,\n",
    "    logging_dir=\"./logs/\"+RUN_NAME,\n",
    "    run_name=RUN_NAME,\n",
    "    bf16=True,\n",
    ")\n",
    "\n",
    "testing_args = TrainingArguments(\n",
    "    per_device_eval_batch_size=BATCH_SIZE[2],\n",
    "    batch_eval_metrics=True,\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5273c531e2c1858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "compute_metrics, compute_results = map_compute_metrics(preprocessor=reference_preprocessor)\n",
    "test_compute_metrics, test_compute_results = map_compute_metrics(preprocessor=test_preprocessor)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=kompstats.train,\n",
    "    eval_dataset=kompstats.valid,\n",
    "    data_collator=partial(collate_fn, preprocessor=reference_preprocessor),\n",
    "    compute_metrics=compute_metrics,\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=30)]\n",
    ")\n",
    "\n",
    "tester = Trainer(\n",
    "    model=model,\n",
    "    args=testing_args,\n",
    "    eval_dataset=kompstats.valid,\n",
    "    data_collator=partial(collate_fn, preprocessor=test_preprocessor),\n",
    "    compute_metrics=test_compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db2a1e328759ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_train():\n",
    "    accelerator = Accelerator()\n",
    "    while True:\n",
    "        try:\n",
    "            try:\n",
    "                print(\"INFO: Trying to resume from previous checkpoint\")\n",
    "                compute_results.reset()\n",
    "                trainer.train(resume_from_checkpoint=True)\n",
    "            except Exception as e:\n",
    "                if \"No valid checkpoint found\" in str(e):\n",
    "                    print(f\"ERROR: Failed to resume from checkpoint - {e}\")\n",
    "                    print(\"INFO: Starting training from scratch\")\n",
    "                    compute_results.reset()\n",
    "                    trainer.train(resume_from_checkpoint=False)\n",
    "        except Exception as e:\n",
    "            if \"CUDA\" in str(e):\n",
    "                print(f\"ERROR: CUDA Error - {e}\")\n",
    "                trainer.train()\n",
    "            else:\n",
    "                raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8127090f2f63c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ADDITIONAL_GPU:\n",
    "    notebook_launcher(start_train, args=(), num_processes=ADDITIONAL_GPU)\n",
    "else:\n",
    "    start_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0aace760f618d0",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b420442c9a00c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b387a431f77f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff6bbc7f16d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 31100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809162a05dd93596",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model = RTDetrForObjectDetection.from_pretrained(f\"{training_args.output_dir}/checkpoint-{checkpoint}/\", torch_dtype=torch.float32, return_dict=True, local_files_only=True)\n",
    "    model.to(device)\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3a7e501e093d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creator-camp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
